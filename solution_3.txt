Task 3 - Q-Learning

Answers:


7) 	Training the Q-learning agent without noise:
        a) Value at state (1, 5): 0.0
        b) Optimal policy : no
        c) Name of parameter: epsilon

8) 	Comparison of values for the start state:
        1) Value of the start state after 300 episodes: -9.85
        2) Average returns from the start state: 2.05
Difference because of many failing possibilities as the proximity to the cliff was very close. Also the epsilon value is quite high such that one in 3 action would be a random action. 

8)  Faster converging algorithm?  =  Value Iteration


